{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加input目录\n",
    "import sys\n",
    "sys.path.append('D:/计算机设计大赛大数据/LBCE-XGB-main/LBCE-XGB-main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV as cc, calibration_curve\n",
    "from Bio import SeqIO\n",
    "from pydpi.pypro import PyPro\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_curve, precision_recall_curve, precision_recall_fscore_support\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, auc, matthews_corrcoef, classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold, LeaveOneOut, train_test_split\n",
    "from sklearn.decomposition import PCA, TruncatedSVD as svd\n",
    "from scipy import interp\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, SelectFromModel\n",
    "#from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import make_scorer\n",
    "import argparse\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = PyPro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAAP(file):  # read AAP features from the AAP textfile\n",
    "    try:\n",
    "        aapdic = {}\n",
    "        aapdata = open(file, 'r')\n",
    "        for l in aapdata.readlines():\n",
    "            aapdic[l.split()[0]] = float(l.split()[1])\n",
    "        aapdata.close()\n",
    "        return aapdic\n",
    "    except:\n",
    "        print(\"Error in reading AAP feature file. Please make sure that the AAP file is correctly formatted\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAAT(file):  # read AAT features from the AAT textfile\n",
    "    try:\n",
    "        aatdic = {}\n",
    "        aatdata = open(file, 'r')\n",
    "        for l in aatdata.readlines():\n",
    "            aatdic[l.split()[0][0:3]] = float(l.split()[1])\n",
    "        aatdata.close()\n",
    "        return aatdic\n",
    "    except:\n",
    "        print(\"Error in reading AAT feature file. Please make sure that the AAT file is correctly formatted\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aap(pep, aapdic, avg):  # return AAP features for the peptides\n",
    "    feature = []\n",
    "    for a in pep:\n",
    "        # print(a)\n",
    "        if int(avg) == 0:\n",
    "            score = []\n",
    "            count = 0\n",
    "            for i in range(0, len(a) - 1):\n",
    "                try:\n",
    "                    score.append(round(float(aapdic[a[i:i + 2]]), 4))\n",
    "                    # score += float(aapdic[a[i:i + 3]])\n",
    "                    count += 1\n",
    "                except KeyError:\n",
    "                    # print(a[i:i + 3])\n",
    "                    score.append(float(-1))\n",
    "                    # score += -1\n",
    "                    count += 1\n",
    "                    continue\n",
    "            # averagescore = score / count\n",
    "            feature.append(score)\n",
    "        if int(avg) == 1:\n",
    "            score = 0\n",
    "            count = 0\n",
    "            for i in range(0, len(a) - 1):\n",
    "                try:\n",
    "                    score += float(aapdic[a[i:i + 2]])\n",
    "                    count += 1\n",
    "                except KeyError:\n",
    "                    score += -1\n",
    "                    count += 1\n",
    "                    continue\n",
    "            if count != 0:\n",
    "                averagescore = score / count\n",
    "            else:\n",
    "                averagescore = 0\n",
    "            feature.append(round(float(averagescore), 4))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aat(pep, aatdic, avg):  # return AAT features for the peptides\n",
    "    feature = []\n",
    "    for a in pep:\n",
    "        if int(avg) == 0:\n",
    "            # print(a)\n",
    "            score = []\n",
    "            count = 0\n",
    "            for i in range(0, len(a) - 2):\n",
    "                try:\n",
    "                    score.append(round(float(aatdic[a[i:i + 3]]), 4))\n",
    "                    # score += float(aapdic[a[i:i + 3]])\n",
    "                    count += 1\n",
    "                except KeyError:\n",
    "                    # print(a[i:i + 3])\n",
    "                    score.append(float(-1))\n",
    "                    # score += -1\n",
    "                    count += 1\n",
    "                    continue\n",
    "            # averagescore = score / count\n",
    "            feature.append(score)\n",
    "        if int(avg) == 1:\n",
    "            score = 0\n",
    "            count = 0\n",
    "            for i in range(0, len(a) - 2):\n",
    "                try:\n",
    "                    score += float(aatdic[a[i:i + 3]])\n",
    "                    count += 1\n",
    "                except KeyError:\n",
    "                    score += -1\n",
    "                    count += 1\n",
    "                    continue\n",
    "            # print(a, score)\n",
    "            if count != 0:\n",
    "                averagescore = score / count\n",
    "            else:\n",
    "                averagescore = 0\n",
    "            feature.append(round(float(averagescore), 4))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTD(pep):  # Chain-Transition-Ditribution feature\n",
    "    feature = []\n",
    "    name = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        ctd = protein.GetCTD()\n",
    "        feature.append(list(ctd.values()))\n",
    "        name = list(ctd.keys())\n",
    "    return feature, name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AAC(pep):  # Single Amino Acid Composition feature\n",
    "    feature = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        aac = protein.GetAAComp()\n",
    "        feature.append(list(aac.values()))\n",
    "        name = list(aac.keys())\n",
    "    return feature, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DPC(pep):  # Dipeptide Composition feature\n",
    "    feature = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        dpc = protein.GetDPComp()\n",
    "        feature.append(list(dpc.values()))\n",
    "        name = list(dpc.keys())\n",
    "    return feature, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAAC(pep):\n",
    "    feature = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        #paac=protein.GetMoranAuto()\n",
    "        paac = protein.GetPAAC(lamda=4)\n",
    "        feature.append(list(paac.values()))\n",
    "        name = list(paac.keys())\n",
    "    return feature, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertfea(file):\n",
    "    feature = []\n",
    "    import joblib\n",
    "    idx_sorted = joblib.load('./shap/CLS.np')\n",
    "    x_test = np.array(pd.read_csv(file,header=None,index_col=None,usecols=[i for i in range(1,769)]))\n",
    "    return x_test[:, idx_sorted[1:131]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QSO(pep):\n",
    "    feature = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        #paac=protein.GetMoranAuto()\n",
    "        qso = protein.GetQSO(maxlag=5)\n",
    "        feature.append(list(qso.values()))\n",
    "        name = list(qso.keys())\n",
    "    return feature, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readpeptides(posfile, negfile):  # return the peptides from input peptide list file\n",
    "    posdata = open(posfile, 'r')\n",
    "    pos = []\n",
    "    for l in posdata.readlines():\n",
    "        if l[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            pos.append(l.strip('\\t0\\n'))\n",
    "    posdata.close()\n",
    "    negdata = open(negfile, 'r')\n",
    "    neg = []\n",
    "    for l in negdata.readlines():\n",
    "        if l[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            neg.append(l.strip('\\t0\\n'))\n",
    "    negdata.close()\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinefeature(pep, featurelist, dataset):\n",
    "    a=np.empty([len(pep), 1])\n",
    "    fname=[]\n",
    "    scaling = StandardScaler()\n",
    "    #pca = svd(n_components=300)\n",
    "    pca = PCA(0.99)\n",
    "    vocab_name = []\n",
    "    #pca = PCA(n_components=10)\n",
    "    #print(a)\n",
    "    if 'aap' in featurelist:\n",
    "        aapdic = readAAP(\"./models/aap-general.txt.normal\")\n",
    "        f_aap = np.array([aap(pep, aapdic, 1)]).T\n",
    "        a = np.column_stack((a,f_aap))\n",
    "        #a = scaling.fit_transform(a)\n",
    "        fname.append('AAP')\n",
    "        #print(f_aap)\n",
    "    if 'aat' in featurelist:\n",
    "        aatdic = readAAT(\"./models/aat-general.txt.normal\")\n",
    "        f_aat = np.array([aat(pep, aatdic, 1)]).T\n",
    "        a = np.column_stack((a, f_aat))\n",
    "        #a = scaling.fit_transform(a)\n",
    "        fname.append('AAT')\n",
    "        #print(f_aat)\n",
    "    if 'dpc' in featurelist:\n",
    "        f_dpc, name = DPC(pep)\n",
    "        # f_dpc = np.average(f_dpc, axis =1)\n",
    "        a = np.column_stack((a, np.array(f_dpc)))\n",
    "        fname = fname + name\n",
    "    if 'aac' in featurelist:\n",
    "        f_aac, name = AAC(pep)\n",
    "        a = np.column_stack((a, np.array(f_aac)))\n",
    "        fname = fname + name\n",
    "    \n",
    "    if 'paac' in featurelist:\n",
    "        f_paac, name = PAAC(pep)\n",
    "        #f_paac = pca.fit_transform(f_paac)\n",
    "        a = np.column_stack((a, np.array(f_paac)))\n",
    "        fname = fname + name\n",
    "   \n",
    "    \n",
    "    if 'qso' in featurelist:\n",
    "        f_qso, name = QSO(pep)\n",
    "        #f_pa = pca.fit_transform(f_paac)\n",
    "        a = np.column_stack((a, np.array(f_qso)))\n",
    "        fname = fname + name\n",
    "\n",
    "    if 'ctd' in featurelist:\n",
    "        f_ctd, name = CTD(pep)\n",
    "        a = np.column_stack((a, np.array(f_ctd)))\n",
    "        fname = fname + name \n",
    "\n",
    "    if 'bertfea' in featurelist:\n",
    "        f_bertfea = np.array(bertfea('./datasets/BERT_feature/training/CLS_fea.txt'))\n",
    "        a = np.column_stack((a, f_bertfea))\n",
    "        fname = fname + ['bertfea']*len(f_bertfea)\n",
    "        \n",
    "    return a[:,1:], fname, vocab_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapdic = readAAP(\"D:/B-cells-TCN/feature-project/models/aap-general.txt.normal\")\n",
    "aatdic = readAAT(\"D:/B-cells-TCN/feature-project/models/aat-general.txt.normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'D:/计算机设计大赛大数据/LBCE-XGB-main/LBCE-XGB-main/datasets'\n",
    "pos, neg = readpeptides(\"D:/B-cells-TCN/feature-project/datasets/iBCE-EL_training/B-positive.txt\",\n",
    "                        \"D:/B-cells-TCN/feature-project/datasets/iBCE-EL_training/B-negative.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aac', 'aap', 'aat', 'bertfea']\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "pep_combined = pos + neg\n",
    "pickle_info={}\n",
    "#print(pep_combined)\n",
    "# aap aat dpc aac paac qso ctd\n",
    "featurelist = ['aac', 'aap', 'aat', 'bertfea']\n",
    "print(featurelist)\n",
    "pickle_info['featurelist'] = featurelist\n",
    "features, fname, vocab = combinefeature(pep_combined, featurelist, dataset) # 'aap', 'aat', 'aac'\n",
    "print(len(features[0]))\n",
    "'''for i in range(len(features)):\n",
    "    print(features[i])'''\n",
    "pickle_info['feat_name'] = fname\n",
    "pickle_info['vocab'] = vocab\n",
    "#pickle.dump(features, open(\"features_latest.pickle\", \"wb\"))\n",
    "#print(features)\n",
    "target = [1] * len(pos) + [0] * len(neg)\n",
    "#print(pep_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7349\n"
     ]
    }
   ],
   "source": [
    "scaling = StandardScaler()\n",
    "scaling.fit(features)\n",
    "print(max(features[:,0]))\n",
    "x= scaling.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('D:/B-cells-TCN/data/allfea.csv',x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7d32af1e689683b59f84af5e00ff8511e054604b74fc1830ce1b819250cf76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
