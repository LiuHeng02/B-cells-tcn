{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/B-cells-TCN') \n",
    "sys.path.append('D:/B-cells-TCN/feature-project') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV as cc, calibration_curve\n",
    "from Bio import SeqIO\n",
    "from pydpi.pypro import PyPro\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_curve, precision_recall_curve, precision_recall_fscore_support\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, auc, matthews_corrcoef, classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold, LeaveOneOut, train_test_split\n",
    "from sklearn.decomposition import PCA, TruncatedSVD as svd\n",
    "from scipy import interp\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, SelectFromModel\n",
    "#from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import make_scorer\n",
    "import argparse\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "protein = PyPro()\n",
    "def readAAT(file):  # read AAT features from the AAT textfile\n",
    "    try:\n",
    "        aatdic = {}\n",
    "        aatdata = open(file, 'r')\n",
    "        for l in aatdata.readlines():\n",
    "            aatdic[l.split()[0][0:3]] = float(l.split()[1])\n",
    "        aatdata.close()\n",
    "        return aatdic\n",
    "    except:\n",
    "        print(\"Error in reading AAT feature file. Please make sure that the AAT file is correctly formatted\")\n",
    "        sys.exit()\n",
    "def readAAP(file):  # read AAP features from the AAP textfile\n",
    "    try:\n",
    "        aapdic = {}\n",
    "        aapdata = open(file, 'r')\n",
    "        for l in aapdata.readlines():\n",
    "            aapdic[l.split()[0]] = float(l.split()[1])\n",
    "        aapdata.close()\n",
    "        return aapdic\n",
    "    except:\n",
    "        print(\"Error in reading AAP feature file. Please make sure that the AAP file is correctly formatted\")\n",
    "        sys.exit()\n",
    "def aap(pep, aapdic, avg):  # return AAP features for the peptides\n",
    "    feature = []\n",
    "    for a in pep:\n",
    "        # print(a)\n",
    "        if int(avg) == 0:\n",
    "            score = []\n",
    "            count = 0\n",
    "            for i in range(0, len(a) - 1):\n",
    "                try:\n",
    "                    score.append(round(float(aapdic[a[i:i + 2]]), 4))\n",
    "                    # score += float(aapdic[a[i:i + 3]])\n",
    "                    count += 1\n",
    "                except KeyError:\n",
    "                    # print(a[i:i + 3])\n",
    "                    score.append(float(-1))\n",
    "                    # score += -1\n",
    "                    count += 1\n",
    "                    continue\n",
    "            # averagescore = score / count\n",
    "            feature.append(score)\n",
    "        if int(avg) == 1:\n",
    "            score = 0\n",
    "            count = 0\n",
    "            for i in range(0, len(a) - 1):\n",
    "                try:\n",
    "                    score += float(aapdic[a[i:i + 2]])\n",
    "                    count += 1\n",
    "                except KeyError:\n",
    "                    score += -1\n",
    "                    count += 1\n",
    "                    continue\n",
    "            if count != 0:\n",
    "                averagescore = score / count\n",
    "            else:\n",
    "                averagescore = 0\n",
    "            feature.append(round(float(averagescore), 4))\n",
    "    return feature\n",
    "def aat(pep, aatdic, avg):  # return AAT features for the peptides\n",
    "    feature = []\n",
    "    for a in pep:\n",
    "        if int(avg) == 0:\n",
    "            # print(a)\n",
    "            score = []\n",
    "            count = 0\n",
    "            for i in range(0, len(a) - 2):\n",
    "                try:\n",
    "                    score.append(round(float(aatdic[a[i:i + 3]]), 4))\n",
    "                    # score += float(aapdic[a[i:i + 3]])\n",
    "                    count += 1\n",
    "                except KeyError:\n",
    "                    # print(a[i:i + 3])\n",
    "                    score.append(float(-1))\n",
    "                    # score += -1\n",
    "                    count += 1\n",
    "                    continue\n",
    "            # averagescore = score / count\n",
    "            feature.append(score)\n",
    "        if int(avg) == 1:\n",
    "            score = 0\n",
    "            count = 0\n",
    "            for i in range(0, len(a) - 2):\n",
    "                try:\n",
    "                    score += float(aatdic[a[i:i + 3]])\n",
    "                    count += 1\n",
    "                except KeyError:\n",
    "                    score += -1\n",
    "                    count += 1\n",
    "                    continue\n",
    "            # print(a, score)\n",
    "            if count != 0:\n",
    "                averagescore = score / count\n",
    "            else:\n",
    "                averagescore = 0\n",
    "            feature.append(round(float(averagescore), 4))\n",
    "    return feature\n",
    "def CTD(pep):  # Chain-Transition-Ditribution feature\n",
    "    feature = []\n",
    "    name = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        ctd = protein.GetCTD()\n",
    "        feature.append(list(ctd.values()))\n",
    "        name = list(ctd.keys())\n",
    "    return feature, name\n",
    "def AAC(pep):  # Single Amino Acid Composition feature\n",
    "    feature = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        aac = protein.GetAAComp()\n",
    "        feature.append(list(aac.values()))\n",
    "        name = list(aac.keys())\n",
    "    return feature, name\n",
    "def DPC(pep):  # Dipeptide Composition feature\n",
    "    feature = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        dpc = protein.GetDPComp()\n",
    "        feature.append(list(dpc.values()))\n",
    "        name = list(dpc.keys())\n",
    "    return feature, name\n",
    "def PAAC(pep):\n",
    "    feature = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        #paac=protein.GetMoranAuto()\n",
    "        paac = protein.GetPAAC(lamda=4)\n",
    "        feature.append(list(paac.values()))\n",
    "        name = list(paac.keys())\n",
    "    return feature, name\n",
    "def bertfea(file):\n",
    "    feature = []\n",
    "    import joblib\n",
    "    idx_sorted = joblib.load('D:/B-cells-TCN/feature-project/shap/CLS.np')\n",
    "    x_test = np.array(pd.read_csv(file,header=None,index_col=None,usecols=[i for i in range(1,769)]))\n",
    "    return x_test[:, idx_sorted[1:131]]\n",
    "def QSO(pep):\n",
    "    feature = []\n",
    "    for seq in pep:\n",
    "        protein.ReadProteinSequence(seq)\n",
    "        #paac=protein.GetMoranAuto()\n",
    "        qso = protein.GetQSO(maxlag=5)\n",
    "        feature.append(list(qso.values()))\n",
    "        name = list(qso.keys())\n",
    "    return feature, name\n",
    "def readpeptides(posfile, negfile):  # return the peptides from input peptide list file\n",
    "    posdata = open(posfile, 'r')\n",
    "    pos = []\n",
    "    for l in posdata.readlines():\n",
    "        if l[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            pos.append(l.strip('\\t0\\n'))\n",
    "    posdata.close()\n",
    "    negdata = open(negfile, 'r')\n",
    "    neg = []\n",
    "    for l in negdata.readlines():\n",
    "        if l[0] == '>':\n",
    "            continue\n",
    "        else:\n",
    "            neg.append(l.strip('\\t0\\n'))\n",
    "    negdata.close()\n",
    "    return pos, neg\n",
    "def combinefeature(pep, featurelist, dataset):\n",
    "    a=np.empty([len(pep), 1])\n",
    "    fname=[]\n",
    "    scaling = StandardScaler()\n",
    "    #pca = svd(n_components=300)\n",
    "    pca = PCA(0.99)\n",
    "    vocab_name = []\n",
    "    #pca = PCA(n_components=10)\n",
    "    #print(a)\n",
    "    if 'aap' in featurelist:\n",
    "        aapdic = readAAP(\"D:/B-cells-TCN/feature-project/models/aap-general.txt.normal\")\n",
    "        f_aap = np.array([aap(pep, aapdic, 1)]).T\n",
    "        a = np.column_stack((a,f_aap))\n",
    "        #a = scaling.fit_transform(a)\n",
    "        fname.append('AAP')\n",
    "        #print(f_aap)\n",
    "    if 'aat' in featurelist:\n",
    "        aatdic = readAAT(\"D:/B-cells-TCN/feature-project/models/aat-general.txt.normal\")\n",
    "        f_aat = np.array([aat(pep, aatdic, 1)]).T\n",
    "        a = np.column_stack((a, f_aat))\n",
    "        #a = scaling.fit_transform(a)\n",
    "        fname.append('AAT')\n",
    "        #print(f_aat)\n",
    "    if 'dpc' in featurelist:\n",
    "        f_dpc, name = DPC(pep)\n",
    "        # f_dpc = np.average(f_dpc, axis =1)\n",
    "        a = np.column_stack((a, np.array(f_dpc)))\n",
    "        fname = fname + name\n",
    "    if 'aac' in featurelist:\n",
    "        f_aac, name = AAC(pep)\n",
    "        a = np.column_stack((a, np.array(f_aac)))\n",
    "        fname = fname + name\n",
    "    \n",
    "    if 'paac' in featurelist:\n",
    "        f_paac, name = PAAC(pep)\n",
    "        #f_paac = pca.fit_transform(f_paac)\n",
    "        a = np.column_stack((a, np.array(f_paac)))\n",
    "        fname = fname + name\n",
    "   \n",
    "    \n",
    "    if 'qso' in featurelist:\n",
    "        f_qso, name = QSO(pep)\n",
    "        #f_pa = pca.fit_transform(f_paac)\n",
    "        a = np.column_stack((a, np.array(f_qso)))\n",
    "        fname = fname + name\n",
    "\n",
    "    if 'ctd' in featurelist:\n",
    "        f_ctd, name = CTD(pep)\n",
    "        a = np.column_stack((a, np.array(f_ctd)))\n",
    "        fname = fname + name \n",
    "\n",
    "    if 'bertfea' in featurelist:\n",
    "        f_bertfea = np.array(bertfea('D:/B-cells-TCN/data/example/exampleCLS_fea.csv'))\n",
    "        a = np.column_stack((a, f_bertfea))\n",
    "        fname = fname + ['bertfea']*len(f_bertfea)\n",
    "        \n",
    "    return a[:,1:], fname, vocab_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapdic = readAAP(\"D:/B-cells-TCN/feature-project/models/aap-general.txt.normal\")\n",
    "aatdic = readAAT(\"D:/B-cells-TCN/feature-project/models/aat-general.txt.normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'D:/计算机设计大赛大数据/LBCE-XGB-main/LBCE-XGB-main/datasets'\n",
    "pos, neg = readpeptides(\"D:/B-cells-TCN/data/example/example_pos.txt\",\n",
    "                        \"D:/B-cells-TCN/data/example/example_neg.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aac', 'aap', 'aat', 'bertfea']\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "pep_combined = pos + neg\n",
    "pickle_info={}\n",
    "#print(pep_combined)\n",
    "# aap aat dpc aac paac qso ctd\n",
    "featurelist = ['aac', 'aap', 'aat', 'bertfea']\n",
    "print(featurelist)\n",
    "pickle_info['featurelist'] = featurelist\n",
    "features, fname, vocab = combinefeature(pep_combined, featurelist, dataset) # 'aap', 'aat', 'aac'\n",
    "print(len(features[0]))\n",
    "'''for i in range(len(features)):\n",
    "    print(features[i])'''\n",
    "pickle_info['feat_name'] = fname\n",
    "pickle_info['vocab'] = vocab\n",
    "#pickle.dump(features, open(\"features_latest.pickle\", \"wb\"))\n",
    "#print(features)\n",
    "target = [1] * len(pos) + [0] * len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaling = StandardScaler()\n",
    "scaling.fit(features)\n",
    "print(max(features[:,0]))\n",
    "x = scaling.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Input, Dense,Activation, BatchNormalization, Conv1D, Conv2D,MaxPooling1D, MaxPooling2D, LSTM, GRU, Embedding, Bidirectional,\n",
    "                         Concatenate,Dropout, Embedding,Convolution1D, Flatten,Layer)\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "# Performance:\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score)\n",
    "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
    "# import pydot_ng as pydot\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)\n",
    "from tensorflow.keras.utils import plot_model,model_to_dot  \n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score, roc_curve, auc)\n",
    "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
    "from layers import MultiHeadAttention,Attention,AttLayer\n",
    "from scipy import interp\n",
    "#from ePooling import GlobalExpectationPooling1D\n",
    "from tcn.tcn import TCN\n",
    "import numpy as np\n",
    "my_seed = 42\n",
    "np.random.seed(my_seed)\n",
    "import random \n",
    "random.seed(my_seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ourmodel():\n",
    "    in_put = Input(shape = (152,1))\n",
    "    a = Convolution1D(128,3,activation='relu',padding='valid')(in_put)\n",
    "    a = BatchNormalization()(a)\n",
    "    b = Convolution1D(128,3,activation='relu',padding='valid')(a)\n",
    "    b = BatchNormalization()(b)\n",
    "    c = Convolution1D(256,3,activation='relu',padding='valid')(b)\n",
    "    c = Dropout(0.7)(c)\n",
    "    c = Reshape((256,146),name='c')(c)\n",
    "    d = TCN(nb_filters=128, kernel_size=5, dropout_rate=0.1, nb_stacks=1,  dilations=[1, 2, 4,8], return_sequences=True,activation='relu',padding='same',use_skip_connections=True)(c)\n",
    "    d = Flatten()(d)\n",
    "    e = Dense(128, activation='relu', name='FC3')(d)\n",
    "    e = Dropout(rate=0.2)(e)\n",
    "    e = Dense(64, activation='relu', name='FC2')(e)\n",
    "    e = Dense(32, activation='relu', name='FC4')(e)\n",
    "    output = Dense(2, activation='softmax', name='Output')(e)\n",
    "\n",
    "    return Model(inputs = [in_put],outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ourmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,data,output_path):\n",
    "    model.load_weights('D:/B-cells-TCN/my_model2/final model/finalModel2.h5')\n",
    "    y_p = model.predict([data])\n",
    "    pt = np.argmax(y_p, axis=1)\n",
    "    output_file = os.path.join(output_path, 'result.txt')\n",
    "    np.savetxt(output_file,pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path='D:/B-cells-TCN/data/example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n"
     ]
    }
   ],
   "source": [
    "predict(model,x,output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
